{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9bAt2wt9cSm"
      },
      "source": [
        "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ5kFtoS9cSp"
      },
      "source": [
        "\n",
        "# Part II: BERT\n",
        "\n",
        "Please see the description of the assignment in the README file (section 2) <br>\n",
        "**Guide notebook**: [guides/bert_guide.ipynb](guides/bert_guide.ipynb)\n",
        "\n",
        "\n",
        "***\n",
        "\n",
        "<br>\n",
        "\n",
        "* Note that you should report results using a classification report.\n",
        "\n",
        "* Also, remember to include some reflections on your results: how do they compare with the results from Part I, BoW? Are there any hyperparameters that are particularly important?\n",
        "\n",
        "* You should follow the steps given in the `bert_guide` notebook\n",
        "\n",
        "* **Optionally**, you can fine-tune a pre-trained BERT model to classify news articles as is done in [guides/bert_guide_finetuning.ipybb](guides/bert_guide_finetuning.ipybb), the same task as in part 1. As this requires more computational resources, this part is optional. If you do decide to complete this part, you will need to use a GPU (e.g., Google Colab) to train the model. (For reference, training on a 2020 Macbook Pro with 16GB RAM and a M1 chip results in an out-of-memory error). Therefore, we suggest that you use Google Colab or another cloud-based service with a GPU. You can easily upload the `bert_guide_finetuning.ipynb` notebook to Google Colab and run it there.\n",
        "\n",
        "<br>\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "dJRGRcYZAQOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "!pip install datasets\n",
        "!pip install torch\n",
        "!pip install evaluate\n",
        "!pip install accelerate\n",
        "!pip install fastparquet\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "q8EXPTahAPY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports for the project"
      ],
      "metadata": {
        "id": "pmZK9KLPAQtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWIst4Wj9cSq"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, ModernBertForSequenceClassification, pipeline, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpqfTep49cSs"
      },
      "source": [
        "### 1. Load the data\n",
        "\n",
        "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
        "\n",
        "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
        "\n",
        "You are welcome to increase the `frac` parameter to load more data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ag_news_train = load_dataset(\"fancyzhx/ag_news\", split=\"train[:10%]\")\n",
        "ag_news_test = load_dataset(\"fancyzhx/ag_news\", split=\"test[:20%]\")\n",
        "ag_news = DatasetDict({\"train\": ag_news_train, \"test\": ag_news_test})\n",
        "ag_news"
      ],
      "metadata": {
        "id": "THsX_9UYAj37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load ModernBERT tokenizer and model from HuggingFace"
      ],
      "metadata": {
        "id": "W-9W2ZVZAs3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mappping from label names to label ids\n",
        "id2label = {\n",
        "    0: 'World',\n",
        "    1: 'Sports',\n",
        "    2: 'Business',\n",
        "    3: 'Sci/Tech'\n",
        "}\n",
        "\n",
        "# Define the mapping from label ids to label names (the reverse of id2label)\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "# load the model\n",
        "model = ModernBertForSequenceClassification.from_pretrained(\"answerdotai/ModernBERT-base\", num_labels=4, id2label=id2label, label2id=label2id)\n",
        "\n",
        "# load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")"
      ],
      "metadata": {
        "id": "oCWUi9YOAsjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize and encode the data"
      ],
      "metadata": {
        "id": "Bb8_X_WwA1n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    \"\"\" Tokenize the text column in the examples. \"\"\"\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_ag_news = ag_news.map(preprocess_function, batched=True, batch_size=4)"
      ],
      "metadata": {
        "id": "ucsDIMrQA3RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set evaluation metric"
      ],
      "metadata": {
        "id": "eQiBNj5oA3uH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    f1 = f1_score(labels, predictions, average='weighted')  # 'weighted' for multiclass\n",
        "    return {\"f1\": f1}"
      ],
      "metadata": {
        "id": "Tc86T7ITA4OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a data collator and mount Google Drive"
      ],
      "metadata": {
        "id": "JGcSRoelBEXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ne_Bi_exBFCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "lDgz3FjJBPVb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akn3zuBa9cSu"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/AIML_2025/ma2/my_awesome_model\",  # THIS NEEDS TO CHANGE ON GOOGLE COLAB: \"/content/drive/MyDrive/Colab Notebooks/my_awesome_model\" or similar. Please check the path.\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.025,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_ag_news[\"train\"],\n",
        "    eval_dataset=tokenized_ag_news[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model"
      ],
      "metadata": {
        "id": "hcfoJOOtBX8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = trainer.predict(tokenized_ag_news[\"train\"])\n",
        "test_predictions = trainer.predict(tokenized_ag_news[\"test\"])\n",
        "\n",
        "# Extract predictions and labels\n",
        "train_preds, train_labels = train_predictions.predictions.argmax(axis=1), train_predictions.label_ids\n",
        "test_preds, test_labels = test_predictions.predictions.argmax(axis=1), test_predictions.label_ids\n",
        "\n",
        "# Classification report for train dataset\n",
        "print(\"Train Classification Report:\")\n",
        "print(classification_report(train_labels, train_preds))\n",
        "\n",
        "# Classification report for test dataset\n",
        "print(\"Test Classification Report:\")\n",
        "print(classification_report(test_labels, test_preds))"
      ],
      "metadata": {
        "id": "mJ3uJ-nfBaAl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}